/* -----------------------------------------------------------------------------
Copyright 2023 Kevin P. Barry

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
----------------------------------------------------------------------------- */

// Author: Kevin P. Barry [ta0kira@gmail.com]

define ZeoliteWhitespace {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, context) (token) {
    \ input.reset()
    token <- empty
    optional Char current <- input.current()
    while (`present` current && CharType.whitespace(`require` current)) {
      current <- input.forward().current()
    }
    scoped {
      String content <- input.take()
    } in if (content.size() > 0) {
      token <- ZeoliteParsed.leaf(label: tokenizerName(), content: content)
    }
  }
}

define ZeoliteLineComment {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, context) (token) {
    \ input.reset()
    token <- empty
    \ input.forward().forward()
    if (input.preview() != "//") {
      return _
    }
    optional Char current <- input.current()
    while (`present` current && !CharType.oneOf(`require` current, "\r\n")) {
      current <- input.forward().current()
    }
    token <- ZeoliteParsed.leaf(label: tokenizerName(), content: input.take())
  }
}

define ZeoliteUpperSymbol {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, _) {
    optional String content <- ZeoliteSymbol.parseUpperSymbol(input)&.take()
    if (! `present` content) {
      return empty
    } else {
      String type <-  ZeoliteSymbol.tryBuiltinCategory(`require` content)
                  <|| "ZeoliteCategoryName"
      return ZeoliteParsed.leaf(label: type, content: `require` content)
    }
  }
}

define ZeoliteLowerSymbol {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, _) {
    optional String content <- ZeoliteSymbol.parseLowerSymbol(input)&.take()
    if (! `present` content) {
      return empty
    } else {
      String type <-  ZeoliteSymbol.tryControlKeyword(`require` content)
                  <|| ZeoliteSymbol.tryTypeKeyword(`require` content)
                  <|| ZeoliteSymbol.tryContainKeyword(`require` content)
                  <|| ZeoliteSymbol.tryBuiltinCategory(`require` content)
                  <|| ZeoliteSymbol.tryBuiltinFunction(`require` content)
                  <|| ZeoliteSymbol.tryBuiltinConstant(`require` content)
                  <|| "ZeoliteFunctionOrVairableName"
      return ZeoliteParsed.leaf(label: type, content: `require` content)
    }
  }
}

define ZeoliteParamName {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, context) {
    optional String content <- ZeoliteSymbol.parseParamName(input)&.take()
    if (! `present` content) {
      return empty
    } else {
      String type <-  ZeoliteSymbol.tryBuiltinParam(`require` content)
                  <|| "ZeoliteParamName"
      return ZeoliteParsed.leaf(label: type, content: `require` content)
    }
  }
}

define ZeoliteBraceSection {
  refines Tokenizer<ZeoliteParseContext, ZeoliteParsed>

  tokenizer () {
    return #self{ }
  }

  tokenizerName () {
    return typename<#self>().formatted()
  }

  tokenize (input, context) (token) {
    \ input.reset()
    token <- empty
    if (input.atEnd() || `require` input.current() != '{') {
      return _
    }
    Vector<ZeoliteParsed> subsections <- Vector<ZeoliteParsed>.new()
    \ subsections.append(ZeoliteParsed.leaf(label: "ZeoliteOpenBrace", content: input.forward().take()))
    \ StreamTokenizer:new(context: context, tokenizer: context.defaultTokenizer()).tokenizeAll(input, subsections)
    \ input.reset()
    if (!input.atEnd() && `require` input.current() == '}') {
      \ subsections.append(ZeoliteParsed.leaf(label: "ZeoliteCloseBrace", content: input.forward().take()))
    }
    token <- ZeoliteParsed.section(label: tokenizerName(), subsections)
  }
}
